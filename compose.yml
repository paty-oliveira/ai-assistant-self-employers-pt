services:
  docs_ingestion:
    build: ./backend
    container_name: ingestion
    command: python -m scripts.ingest_docs
    environment:
      - LLAMA_CLOUD_API_KEY=${LLAMA_CLOUD_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    env_file:
      - .env
    volumes:
      - ./backend/state:/app/backend/state
      - ./backend:/app/backend

  api:
    build: ./backend
    container_name: api
    ports:
      - "8000:80"
    environment:
      - LLAMA_CLOUD_API_KEY=${LLAMA_CLOUD_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    env_file:
      - .env
    volumes:
      - ./backend:/app/backend
    restart: unless-stopped
    depends_on:
      docs_ingestion:
        condition: service_completed_successfully

  app:
    build: ./frontend
    container_name: app
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://api:80
    volumes:
      - ./frontend:/app/frontend
    restart: unless-stopped
    depends_on:
      - api
