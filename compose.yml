services:
  docs_ingestion:
    build: ./backend
    container_name: docs_ingestion
    command: python -m scripts.ingest_docs
    environment:
      - LLAMA_CLOUD_API_KEY=${LLAMA_CLOUD_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    env_file:
      - .env
    volumes:
      - ./backend:/app/backend

  backend:
    build: ./backend
    container_name: api
    ports:
      - "8000:80"
    environment:
      - LLAMA_CLOUD_API_KEY=${LLAMA_CLOUD_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    env_file:
      - .env
    volumes:
      - ./backend:/app/backend
    restart: unless-stopped
    depends_on:
      docs_ingestion:
        condition: service_completed_successfully
